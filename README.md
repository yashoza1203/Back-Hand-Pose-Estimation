# ğŸ–ï¸ Back-Hand Pose Estimation

This project explores back-hand keypoint estimation using CNN-based models trained on the **Thumb Index 1k** dataset.

---

## ğŸ“‚ Models Trained

### 1. âœ… EfficientNet B0 (PyTorch)
- **Framework**: PyTorch
- **Hand Detection**: Accurate
- **Keypoint Estimation**: Poor performance
- **Inference Speed**: ~15 FPS on CPU
- **Observation**: Detects hands reliably but struggles with accurate keypoint estimation.

---

### 2. âœ… ResNet-50 (Keras)
- **Framework**: Keras
- **Hand Detection**: Accurate
- **Keypoint Estimation**: Moderate performance
- **Inference Speed**: ~1 FPS on CPU
- **Observation**: Decent accuracy, but too slow for real-time applications.

---

### 3. âœ… YOLOv8 Pose (n, s, m, x)
- **Framework**: Ultralytics YOLOv8
- **Image Sizes**: 224Ã—224 and 640Ã—640
- **Best Performance**: Models trained with 224Ã—224 images
- **Detection**: Accurate and consistent
- **Keypoint Estimation**: Highly precise
- **Top Performer**: `YOLOv8n` @ 224Ã—224 â†’ **30 FPS on CPU**
- **Observation**: Smaller image sizes improved FPS significantly without compromising keypoint accuracy.

---

## ğŸ” Next Steps / To-Do

To make this project even more robust, consider adding:

- ğŸ“Š **Evaluation Metrics**: PCK, mAP, or custom accuracy metrics for keypoint localization.
- ğŸ“ **Dataset Overview**: Size, annotation format, pose diversity, and augmentation details.
- ğŸ‹ï¸ **Training Info**: Epochs, batch size, learning rate, optimizer, training time, and hardware specs.
- ğŸ–¼ï¸ **Visual Outputs**: Example images showing predicted keypoints vs. ground truth.
- ğŸ“‰ **Error Analysis**: Where models failâ€”occlusions, low light, extreme poses, etc.
- ğŸ“‹ **Model Comparison Table**: Parameters, FPS, accuracy, model size, etc.
- ğŸ› ï¸ **Applications**: Real-time gesture tracking, human-computer interaction, etc.

---

## ğŸ“Œ Contributing

Feel free to fork the repo, open issues, or submit PRs! Any improvements, new models, or suggestions are welcome.

---

## ğŸ“„ License

This project is licensed under [MIT License](LICENSE).
